{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba70357-2abe-4147-ba65-33bc7af63b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import mariadb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b2d3ac0-d37b-4fa2-b377-db4a1db5c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to show all the columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4ecf3-7171-40f4-81b5-cccb6277937e",
   "metadata": {},
   "source": [
    "## 1. Trip_info\n",
    "(nTrips and NightEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f887f8b-3a5d-4d8e-8d83-b5200756e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull trip_info data\n",
    "cur.execute(\"SELECT * FROM trip_info WHERE tripStartTime >= '2022-07-01 00:00:00' AND tripStartTime <= '2024-07-01 00:00:00' ORDER BY tripStartTime desc\")\n",
    "trip_info_data = pd.DataFrame(cur.fetchall())\n",
    "conn.commit()\n",
    "\n",
    "trip_info_data.columns = (\"trip_id\", \"vehicleName\", \"groupId\", \"groupName\", \"occupants\", \"tripStartLatitude\", \"tripStartLongitude\", \"tripStartTime\",\n",
    "                         \"tripStartOffset\", \"tripStartAddress\", \"tripEndLatitude\", \"tripEndLongitude\", \"tripEndTime\", \"tripEndOffset\", \"tripEndAddress\",\n",
    "                         \"stopTime\", \"distanceTravelled\", \"tripNumber\", \"tripTime\", \"idleTime\", \"hardBrakingCount\", \"hardCoreBrakingCount\", \"hardAccelerationCount\",\n",
    "                         \"overspeedingCount\", \"overspeedingDuration\", \"corneringCount\", \"maximumSpeed\", \"averageSpeed\", \"fuelConsumed\", \"participantId\", \"beaconIssued\",\n",
    "                         \"beaconDetected\", \"tripLocalStartDate\", \"tripLocalStartTime\", \"weekNumber\", \"tripLocalEndDate\", \"tripLocalEndTime\", \"SunRise\", \"SunSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "69c7461a-66c1-4e82-97f7-bad355dfd981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1054391, 19)\n",
      "(973641, 19)\n"
     ]
    }
   ],
   "source": [
    "trip_info = trip_info_data[[\n",
    " 'trip_id',\n",
    " 'vehicleName',\n",
    " 'tripStartTime',\n",
    " 'distanceTravelled',\n",
    " 'tripNumber',\n",
    " 'tripTime',\n",
    " 'hardBrakingCount',\n",
    " 'hardCoreBrakingCount',\n",
    " 'hardAccelerationCount',\n",
    " 'overspeedingCount',\n",
    " 'corneringCount',\n",
    " 'maximumSpeed',\n",
    " 'averageSpeed',\n",
    " 'participantId',\n",
    " 'tripLocalStartDate',\n",
    " 'tripLocalStartTime',\n",
    " 'tripLocalEndTime',\n",
    " 'SunRise',\n",
    " 'SunSet']].copy()\n",
    "\n",
    "print(trip_info.shape)\n",
    "\n",
    "# Remove trips without movements (use distanceTravelled)\n",
    "trip_info = trip_info.loc[trip_info['distanceTravelled'] > 0]\n",
    "# Remove trips without time changed (use triptime)\n",
    "trip_info = trip_info.loc[trip_info['tripTime'] > 0]\n",
    "\n",
    "print(trip_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8567b2f3-42d1-4675-bd8f-913d3d7fc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract year and month and convert 'year', 'month', 'vehicleName' to string\n",
    "def preprocess_dataframe(trip_info):\n",
    "    # Convert 'tripStartTime' to datetime\n",
    "    trip_info['tripStartTime'] = pd.to_datetime(trip_info['tripStartTime'])\n",
    "    \n",
    "    # Extract year and month\n",
    "    trip_info.loc[:,'year'] = trip_info['tripStartTime'].dt.year.astype(str)\n",
    "    trip_info.loc[:,'month'] = trip_info['tripStartTime'].dt.month.astype(str)\n",
    "    trip_info.loc[:,'day'] = trip_info['tripStartTime'].dt.day.astype(str)\n",
    "    # Convert 'vehicleName' to string\n",
    "    trip_info.loc[:,'vehicleName'] = trip_info['vehicleName'].astype(str)\n",
    "\n",
    "    return trip_info\n",
    "\n",
    "# apply the function to df\n",
    "trip_info = preprocess_dataframe(trip_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c4ef33d9-bf77-423a-8b3c-5a8c386e854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new column 'vid' by concatenating 'vehicleName', 'year' and 'month'\n",
    "trip_info = trip_info.assign(vid=trip_info['vehicleName'] + '_' + trip_info['year'] + '_' + trip_info['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "746daf0d-6b4c-4b7d-b4b6-327193ceb3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nTrips\n",
    "# Initialize target subgroup columns with zeros\n",
    "trip_info.loc[:,'tripsmaller1mile'] = 0\n",
    "trip_info.loc[:,'tripCount1to5miles'] = 0\n",
    "trip_info.loc[:,'tripCount5to10miles'] = 0\n",
    "trip_info.loc[:,'tripCount10to20miles'] = 0\n",
    "trip_info.loc[:,'tripCount20plusmiles'] = 0\n",
    "\n",
    "# Categorize trips into subgroups based on distance travelled\n",
    "for index, row in trip_info.iterrows():\n",
    "    distance = row['distanceTravelled']\n",
    "    if distance < 1:\n",
    "        trip_info.at[index, 'tripsmaller1mile'] = 1\n",
    "    elif 1 <= distance < 5:\n",
    "        trip_info.at[index, 'tripCount1to5miles'] = 1\n",
    "    elif 5 <= distance < 10:\n",
    "        trip_info.at[index, 'tripCount5to10miles'] = 1\n",
    "    elif 10 <= distance < 20:\n",
    "        trip_info.at[index, 'tripCount10to20miles'] = 1\n",
    "    else:\n",
    "        trip_info.at[index, 'tripCount20plusmiles'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d61d0011-be2a-4a99-9135-92b9fc8a0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nightEvent\n",
    "# Convert start time, end time, sunrise and sunset to string\n",
    "trip_info['tripLocalStartTime'] = trip_info['tripLocalStartTime'].astype(str)\n",
    "trip_info['tripLocalEndTime'] = trip_info['tripLocalEndTime'].astype(str)\n",
    "trip_info['SunRise'] = trip_info['SunRise'].astype(str)\n",
    "trip_info['SunSet'] = trip_info['SunSet'].astype(str)\n",
    "# Convert start time, end time, sunrise and sunset to datetime format\n",
    "trip_info.loc[:,'tripLocalStartTime'] = trip_info['tripLocalStartTime'].str.strip()\n",
    "trip_info.loc[:,'tripLocalEndTime'] = trip_info['tripLocalEndTime'].str.strip()\n",
    "\n",
    "trip_info.loc[:,'tripLocalStartTime'] = trip_info['tripLocalStartTime'].str[-8:]\n",
    "trip_info.loc[:,'tripLocalEndTime'] = trip_info['tripLocalEndTime'].str[-8:]\n",
    "\n",
    "trip_info.loc[:,'tripLocalStartTime'] = pd.to_datetime(trip_info['tripLocalStartTime'], format='%H:%M:%S').dt.time\n",
    "trip_info.loc[:,'tripLocalEndTime'] = pd.to_datetime(trip_info['tripLocalEndTime'], format='%H:%M:%S').dt.time\n",
    "\n",
    "trip_info.loc[:,'SunRise'] = trip_info['SunRise'].str.strip()\n",
    "trip_info.loc[:,'SunSet'] = trip_info['SunSet'].str.strip()\n",
    "\n",
    "trip_info.loc[:,'SunRise'] = trip_info['SunRise'].str[-8:]\n",
    "trip_info.loc[:,'SunSet'] = trip_info['SunSet'].str[-8:]\n",
    "\n",
    "trip_info.loc[:,'SunRise'] = pd.to_datetime(trip_info['SunRise'], format='%H:%M:%S').dt.time\n",
    "trip_info.loc[:,'SunSet'] = pd.to_datetime(trip_info['SunSet'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Function to determine if a trip is a night event\n",
    "def is_day_event(row):\n",
    "    return (row['tripLocalStartTime'] > row['SunRise']) and (row['tripLocalEndTime'] < row['SunSet'])\n",
    "\n",
    "#create a new column 'night_event'\n",
    "trip_info['night_event'] = trip_info.apply(lambda row: 0 if is_day_event(row) else 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ca444-e49b-4c25-89b2-9e2dcd3a9702",
   "metadata": {},
   "source": [
    "### 2. Monthly Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c503b8a-86ba-4395-a2a3-317f498d523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull mobility_metrics_monthly data\n",
    "cur.execute(\"SELECT * FROM mobility_metrics_monthly WHERE CASE WHEN RIGHT(yearMonth,2) IN (10,11,12) THEN CONCAT(yearMonth,'-01') ELSE CONCAT(CONCAT(LEFT(yearMonth,5),CONCAT('0',RIGHT(yearMonth,1))),'-01') END >= '2022-07-01' AND CASE WHEN RIGHT(yearMonth,2) IN (10,11,12) THEN CONCAT(yearMonth,'-01') ELSE CONCAT(CONCAT(LEFT(yearMonth,5),CONCAT('0',RIGHT(yearMonth,1))),'-01') END <= '2024-07-01' ORDER BY yearMonth DESC\")\n",
    "mobility_data = pd.DataFrame(cur.fetchall())\n",
    "conn.commit()\n",
    "\n",
    "mobility_data.columns = (\n",
    " 'vehicleName',\n",
    " 'yearMonth',\n",
    " 'tripCount',\n",
    " 'homeLatitude',\n",
    " 'homeLongitude',\n",
    " 'radiusOfGyration',\n",
    " 'radiusOfGyration_2k',\n",
    " 'radiusOfGyration_3k',\n",
    " 'radiusOfGyration_4k',\n",
    " 'maxDistanceFromHome',\n",
    " 'maxDistance',\n",
    " 'numberOfUniqueDestinations',\n",
    " 'randomEntropy',\n",
    " 'realEntropy',\n",
    " 'uncorrelatedEntropy',\n",
    " 'DRIVESentropy')\n",
    "\n",
    "# drop test vehicle\n",
    "mobility_data = mobility_data[~mobility_data['vehicleName'].isin(['Ganesh B Test for Da', 'Sarah Test for Dashc', 'Study Vehicle'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3254d227-a382-4d07-80b7-c82698c30724",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility = mobility_data[[\n",
    "'vehicleName', \n",
    "'yearMonth', \n",
    "'tripCount', \n",
    "'radiusOfGyration', \n",
    "'numberOfUniqueDestinations', \n",
    "'realEntropy', \n",
    "'randomEntropy', \n",
    "'maxDistanceFromHome', \n",
    "#'maxDistance' # has missing data, so we won't use variable here\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f99b966-ae3b-4b73-b19f-c0bb65a87afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime format\n",
    "mobility['yearMonth'] = pd.to_datetime(mobility['yearMonth'], format='%Y-%m')\n",
    "\n",
    "# Create 'year' and 'month' columns\n",
    "mobility['year'] = mobility['yearMonth'].dt.year\n",
    "mobility['month'] = mobility['yearMonth'].dt.month\n",
    "\n",
    "# Convert 'vehicleName' to string\n",
    "mobility.loc[:,'year'] = mobility['year'].astype(str)\n",
    "mobility.loc[:,'month'] = mobility['month'].astype(str)\n",
    "mobility.loc[:,'vehicleName'] = mobility['vehicleName'].astype(str)\n",
    "\n",
    "# add vid as the key\n",
    "# Create the new column 'vid' by concatenating 'vehicleName' and 'month'\n",
    "mobility = mobility.assign(vid=mobility['vehicleName'] + '_' + mobility['year'] + '_' + mobility['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "57d2ac92-b22c-4099-a6a9-53ad340fe4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two observations for 2024-2, keeping the first occurrence\n",
    "mobility = mobility.sort_values(by= ['vehicleName', 'year', 'month']) \\\n",
    "               .drop_duplicates(subset=['vehicleName', 'year', 'month'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d007ca-5802-47aa-a552-cc381246f969",
   "metadata": {},
   "source": [
    "### 3. Calculated Driving Features and Merge All Driving Features (calculated from mobility and trip_info) into one df\n",
    "('nHardcoreBrake',\r\n",
    "'nHardcornering',\r\n",
    "'randomEntropy',\r\n",
    "'nDaysDriven',\r\n",
    "'nTrips_1mi',\r\n",
    "'nTrips_1to5mi',\r\n",
    "'radiusOfGyration',\r\n",
    "'maxDistanceFromHome',\r\n",
    "'maxDistance',\r\n",
    "'numberOfUniqueDestnt',\r\n",
    "'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e579cc-95b6-4745-96e2-e0afa12d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is one vehicle shared by one than one px\n",
    "v_p_counts = trip_info.groupby('vehicleName')['participantId'].nunique()\n",
    "\n",
    "# Filter groups where the count of unique participant IDs is greater than 1\n",
    "vehicles_with_multiple_participants = v_p_counts[v_p_counts > 1]\n",
    "\n",
    "# Print the vehicle names with multiple participant IDs\n",
    "print(vehicles_with_multiple_participants)\n",
    "\n",
    "# To maintian our data quality, all the vehicles shared by multiple px were removed\n",
    "trip_info['vehicleName'] = trip_info['vehicleName'].astype(str)\n",
    "# removed both of the observations when two partcipants sharing one vehicle\n",
    "trip_info = trip_info[trip_info['vehicleName'] != '']\n",
    "trip_info = trip_info[trip_info['vehicleName'] != '']\n",
    "trip_info = trip_info[trip_info['vehicleName'] != '']\n",
    "trip_info = trip_info[trip_info['vehicleName'] != '']\n",
    "trip_info = trip_info[trip_info['vehicleName'] != '']\n",
    "trip_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "90a79148-455b-415d-a189-33d29519b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove px is 0\n",
    "trip_info = trip_info[trip_info['participantId'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7c15c837-ae7d-4ee2-970c-804b36a3812e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nDaysDriven\n",
    "# Group by 'vid' and 'year_month', and count unique days\n",
    "days_driven_per_month = trip_info.groupby(['participantId','year', 'month'])['day'].nunique().reset_index()\n",
    "# Rename the column to 'Days_driven_per_month'\n",
    "days_driven_per_month.rename(columns={'day': 'Days_driven_per_month'}, inplace=True)\n",
    "# Merge this new column back into the trip_info\n",
    "trip_info = pd.merge(trip_info, days_driven_per_month, on=['vid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "81cdd6b4-bb86-4a30-80ca-669f1ee2fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate featured for each vehicle and each month (vid = vehicleName + year + month)\n",
    "vehicle_indct = trip_info.groupby(['vid']).agg(\n",
    "    TotalDist=('distanceTravelled', 'sum'), # Total distance travelled monthly during the study period\n",
    "    nTrips_1mi=('tripsmaller1mile', 'sum'), # The total number of trips with a distance smaller than 1 mi \n",
    "    nTrips_1to5mi=('tripCount1to5miles', 'sum'), \n",
    "    maxDistance=('distanceTravelled', 'max'),# The maxium distance traveled in a month, not using mobility data because there is missing in mobility\n",
    "    nHardcoreBrake=('hardCoreBrakingCount', 'sum'), # The total number of hardcore braking\n",
    "    nHardcornering=('corneringCount', 'sum'), # The total number of hard cornering\n",
    ").reset_index()\n",
    "\n",
    "# Calculate hardcorebraking and nHardcornering per mile\n",
    "vehicle_indct['nHardcoreBrake'] = vehicle_indct['nHardcoreBrake'] / vehicle_indct['TotalDist']\n",
    "vehicle_indct['nHardcornering'] = vehicle_indct['nHardcornering'] / vehicle_indct['TotalDist']\n",
    "\n",
    "# Add vehicleId back by merging\n",
    "vehicle_mapping = trip_info[['participantId', 'vehicleName']].drop_duplicates()\n",
    "vehicle_indct = vehicle_indct.merge(vehicle_mapping, on='participantId', how='left')\n",
    "\n",
    "# add the nDaysDriven to vehicle_indct\n",
    "vehicle_indct = pd.merge(vehicle_indct, days_driven_per_month, on=['vid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b91d9-bbd0-4a96-a820-8bf250e58878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vehicle_indct and mobility to one dataframe based on the vid. \n",
    "tmp_driving_features = pd.merge(vehicle_indct, mobility, left_on='vid', right_on='vid', how='inner').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe46af5-1936-490d-81df-771cfc3005c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_features = tmp_driving_features[['vid',\n",
    "                                         'vehicleName', \n",
    "                                             'nHardcoreBrake',\n",
    "                                             'nHardcornering',\n",
    "                                             'Days_driven_per_month',\n",
    "                                             'nTrips_1mi',\n",
    "                                             'nTrips_1to5mi',\n",
    "                                             'randomEntropy',\n",
    "                                             'radiusOfGyration',\n",
    "                                             'maxDistanceFromHome',\n",
    "                                             'maxDistance',\n",
    "                                             'numberOfUniqueDestinations',\n",
    "                                             'year',\n",
    "                                             'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70552e7b-6bd7-4aa0-b26e-604a205d08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915d8d2-35a5-45c5-b92e-387a651cea0c",
   "metadata": {},
   "source": [
    "### 4. Static - merged in to one df - 'meds_demo_dp_pure'\n",
    "PHQ-9, dp status, demographics, medications\n",
    "- PHQ9: https://redcap.wustl.edu/redcap/redcap_v14.0.34/DataExport/index.php?pid=6785 \n",
    "- dp status: from G on Mar 14th\n",
    "- demographics: https://redcap.wustl.edu/redcap/redcap_v14.0.34/DataExport/index.php?pid=7842\n",
    "- medications: from G on July 11th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2fe828-6a64-4368-a63a-30a59e40f61e",
   "metadata": {},
   "source": [
    "##### 4.1 PHQ-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "637cbd6a-8aa1-4d32-86e2-8fe73166af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phq9 = pd.read_csv('.../PHQ9_20240822.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2358160-cc09-4721-a4bb-15e256c19679",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = input_phq9[[\n",
    "'map_id', \n",
    "'redcap_event_name', \n",
    "'phq_totscore', \n",
    "'otdate'\n",
    "]].copy()\n",
    "\n",
    "# remove NA data\n",
    "tmp.dropna(inplace=True)\n",
    "# change the dtype to datetime\n",
    "tmp['otdate'] = pd.to_datetime(tmp['otdate'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6f6bf54-20f2-49a0-91f4-367a5dd696ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target date\n",
    "target_date = pd.to_datetime('2022-07-01')\n",
    "\n",
    "# Define a function to find the row of data that closest to the target date \n",
    "def closest_date(row):\n",
    "    return row.loc[row['otdate'].sub(target_date).abs().idxmin()]\n",
    "\n",
    "# Apply the function to each px(id) \n",
    "closest_rows = tmp.groupby('map_id').apply(closest_date).reset_index(drop=True)\n",
    "\n",
    "# Create a new df with the rows with closest date\n",
    "phq9 = pd.DataFrame(closest_rows)\n",
    "\n",
    "phq9 = phq9[['map_id', 'phq_totscore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43c538-ffd6-4ed2-9f4f-832ca39de1e4",
   "metadata": {},
   "source": [
    "##### 4.2 dp status\n",
    "(merge phq9 to dp, keep pure controls-non-depression and PHQ9=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0456fe04-63aa-43d1-8c59-6dca7831c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dp = pd.read_csv('.../id_395.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f29640f-cc66-4c7d-9e07-3beef6e4355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = input_dp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "422d6ca7-201d-47e0-82e0-7be1d43443b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to dp\n",
    "tmp_dp_phq = pd.merge(dp, phq9, left_on='id', right_on='map_id', how='left').reset_index(drop = True)\n",
    "tmp_dp_phq = tmp_dp_phq.drop(['map_id', 'Obs'], axis=1)\n",
    "\n",
    "# Drop if the dp = no and Total score not equals to 0\n",
    "tmp_dp_phq = tmp_dp_phq[~((tmp_dp_phq['dp'] == 'no') & (tmp_dp_phq['phq_totscore'] != 0))].copy()\n",
    "dp_pure = tmp_dp_phq.drop(['phq_totscore'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3274cfd-8cb7-4587-9106-87581dbfd4a9",
   "metadata": {},
   "source": [
    "##### 4.3 Demographics\n",
    "(gender, educ, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b172bf0-0cd0-4913-b42c-04368dc5b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_demo = pd.read_csv('.../Static_20240822.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71ea46d2-d5b5-4dac-bfa7-0523cf49376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_demo = input_demo[['id', \n",
    "                       'gender',\n",
    "                       'educ',\n",
    "                       'birth'\n",
    "                      ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66f1c71e-2745-4e83-a9a5-7195ae228ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target date\n",
    "target_date = pd.to_datetime('2022-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d942ab45-4022-46a2-ac76-0f0966c0d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate age\n",
    "def calculate_age(birth):\n",
    "    #today = datetime.today()\n",
    "    # Set today's date to 2024-09-03\n",
    "    #today = datetime(2024, 9, 3)\n",
    "    age = target_date.year - birth.year - ((target_date.month, target_date.day) < (birth.month, birth.day))\n",
    "    return age\n",
    "\n",
    "# Convert the 'birth' column to datetime\n",
    "tmp_demo['birth'] = pd.to_datetime(tmp_demo['birth'])\n",
    "\n",
    "# Create 'age' column by applying the calculate_age function\n",
    "tmp_demo['age'] = tmp_demo['birth'].apply(calculate_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2ed237c-0b4b-47af-ae9f-be9b52c50763",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = tmp_demo[['id', 'gender', 'educ', 'age']].copy()\n",
    "# merge demo score to driving\n",
    "demo_dp_pure = pd.merge(dp_pure, demo, left_on='id', right_on='id', how='left').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "18160602-b663-47df-932e-3123dce466bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.34705882352941"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dp_pure[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a51c7ec-c754-4449-8025-a07ec8d2316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.689460581856214"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dp_pure[\"age\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bdff0-bdcf-4f53-8f16-fe7e27d4d2b6",
   "metadata": {},
   "source": [
    "##### 4.4 Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3e17f-adad-4c35-a5e9-66a16c37b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meds = pd.read_csv('.../Meds_20240911.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b4a28-9b98-4232-848d-9914beb03083",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_meds = input_meds.copy()\n",
    "# Convert columns to numeric \n",
    "temp_meds['MAO.inhibitors'] = pd.to_numeric(temp_meds['MAO.inhibitors'])\n",
    "temp_meds['SSRI.SNRI'] = pd.to_numeric(temp_meds['SSRI.SNRI'])\n",
    "temp_meds['TCAs'] = pd.to_numeric(temp_meds['TCAs'])\n",
    "\n",
    "temp_meds['Anticonvulsants'] = pd.to_numeric(temp_meds['Anticonvulsants'])\n",
    "temp_meds['Antipsychotics'] = pd.to_numeric(temp_meds['Antipsychotics'])\n",
    "temp_meds['Benzodiazepine'] = pd.to_numeric(temp_meds['Benzodiazepine'])\n",
    "temp_meds['Non.Benzo.Hypnotics.Sedatives'] = pd.to_numeric(temp_meds['Non.Benzo.Hypnotics.Sedatives'])\n",
    "temp_meds['CNS.drugs'] = pd.to_numeric(temp_meds['CNS.drugs'])\n",
    "temp_meds['Opioids'] = pd.to_numeric(temp_meds['Opioids'])\n",
    "temp_meds['NSAID.APAP'] = pd.to_numeric(temp_meds['NSAID.APAP'])\n",
    "\n",
    "# caluculate Antidepressants and Total Meds\n",
    "#Antidepressant = MAO.inhibitors+SSRI.SNRI+TCAs\n",
    "temp_meds['Antidepressant'] = [\n",
    "    1 if (temp_meds.iloc[i]['MAO.inhibitors'] == 1 or \n",
    "              temp_meds.iloc[i]['SSRI.SNRI'] == 1 or \n",
    "              temp_meds.iloc[i]['TCAs'] == 1) else 0\n",
    "    for i in range(len(temp_meds))\n",
    "]\n",
    "\n",
    "#Total = Anticonvulsants + Antipsychotics + Benzodiazepine + Non_Benzo_Hypnotics + CNS_drugs +  Opioids +  Antidepressant + NSAID_APAP\n",
    "temp_meds['Total']= (temp_meds['Anticonvulsants'] + temp_meds['Antipsychotics'] + temp_meds['Benzodiazepine'] + temp_meds['Non.Benzo.Hypnotics.Sedatives']\n",
    "+ temp_meds['CNS.drugs'] + temp_meds['Opioids']+ temp_meds['Antidepressant'] + temp_meds['NSAID.APAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f1ce3-3d60-4c12-9476-6f55bb2bac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the row closest to the target date for each map_id\n",
    "def closest_date_meds(row):\n",
    "    return row.loc[row['testdate'].sub(target_date).abs().idxmin()]\n",
    "\n",
    "temp_meds['testdate'] = pd.to_datetime(temp_meds['testdate'])\n",
    "\n",
    "# Apply the function closest_date to each group (id) using groupby\n",
    "closest_rows_meds = temp_meds.groupby('id').apply(closest_date_meds)\n",
    "\n",
    "# Create a new DataFrame with the closest rows\n",
    "temp_meds_2 = pd.DataFrame(closest_rows_meds)\n",
    "\n",
    "meds = temp_meds_2[ ['id', 'Antidepressant', 'Total'] ].drop_duplicates().reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f161fa1-1c48-417e-9c3d-65ad8630befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge meds to demo_dp_pure\n",
    "meds_demo_dp_pure = pd.merge(demo_dp_pure, meds, left_on='id', right_on='id', how='left').drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef60f3-09a8-4543-9183-2704b585270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure both df has the same key 'vid'\n",
    "id_vid = trip_info[['vid', 'participantId']].drop_duplicates().reset_index(drop = True)\n",
    "id_vid['participantId'] = pd.to_numeric(id_vid['participantId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595bb5f-c41c-4df3-b496-e58ec69451a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge static features together\n",
    "static_features = pd.merge(meds_demo_dp_pure, id_vid, left_on='id', right_on='participantId', how='left').drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd477a5-5569-4888-b12b-014ea0bdd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_demo_dp_pure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5b4ce-0733-4cb3-b262-7f979060d994",
   "metadata": {},
   "source": [
    "#### 5. Merge both static df and Driving features to one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca8773-4fef-4751-b0c0-2d6017c2436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing\n",
    "check1 = static_features.isnull().sum()\n",
    "print(check1)\n",
    "\n",
    "check2 = driving_features.isnull().sum()\n",
    "print(check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09a431-063b-45ca-b3b3-64147ee7b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "df = pd.merge(static_features, driving_features, left_on='vid', right_on='vid', how='inner').drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56394f-ff43-4db0-9dda-c608e80e0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a76ea1-76af-4249-9ac5-797c44a549f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = df.isnull().sum()\n",
    "print(check_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a3404-e75c-41ef-a06f-1c137d8f57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing meds with 0\n",
    "df['Total'].fillna(0, inplace=True)\n",
    "df['Antidepressant'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de449b-481e-4b55-b775-5b701404a674",
   "metadata": {},
   "source": [
    "#### 6. Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58eed94-0ff5-478d-a87c-7d5506939a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = df['dp'] == 'yes'\n",
    "print(f\"Number of depressed px in df: {yes.sum()}\")\n",
    "\n",
    "no = df['dp'] =='no'\n",
    "print(f\"Number of non-depressed px in df: {no.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733d2ea-7df3-4426-8fbc-f42b143fcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dp description of df groupby unique id\n",
    "df.groupby('participantId')['dp'].agg(lambda x: x.value_counts().index[0])\n",
    "# count how many are yes and how many are no groupby unique id\n",
    "df_dp_count = df.groupby('participantId')['dp'].agg(lambda x: x.value_counts().index[0]).value_counts()\n",
    "print(df_dp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d50ccf-3e3e-4a10-9f07-2b91f6850453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d713475-b2fe-40cf-971e-d126dbaf5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[[\n",
    "'participantId',\n",
    "'vehicleName',\n",
    "# 'id',\n",
    " 'dp',\n",
    " 'gender',\n",
    " 'educ',\n",
    " 'age',\n",
    " 'Antidepressant',\n",
    " 'Total',\n",
    "# 'vid',\n",
    " 'nHardcoreBrake',\n",
    " 'nHardcornering',\n",
    " 'Days_driven_per_month',\n",
    " 'nTrips_1mi',\n",
    " 'nTrips_1to5mi',\n",
    " 'randomEntropy',\n",
    " 'radiusOfGyration',\n",
    " 'maxDistanceFromHome',\n",
    " 'maxDistance',\n",
    " 'numberOfUniqueDestinations',\n",
    " 'year',\n",
    " 'month'\n",
    "]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bd58bd4-74ae-4683-90bd-f295f907a0a1",
   "metadata": {},
   "source": [
    "# export\n",
    "file_path = os.path.join(directory, \"driving_static_data_20250108.csv\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_final.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e23e2-5f24-4f99-9e6e-0983ebb689ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3516ce-f076-4c3f-91c8-1ee9a0dca07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
